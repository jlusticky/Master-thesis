%=========================================================================
% (c) 2014, 2015 Josef Lusticky

\section{Ingress traffic processing}\label{sec:linux-ingress}
The traditional way of processing frames from NIC is interrupt-driven~\cite{linux-kernel-networking}.
Each incoming frame is an asynchronous event which raises a hardware interrupt.
Interrupt handlers run asynchronously with either the current interrupt level disabled or with all
interrupts disabled~\cite{lkd2}.
The handlers could interrupt other potentially important code, therefore they need to run as quickly as possible.
Interrupt handlers immediately respond to hardware and perform time-critical actions,
however, other less critical work should be deferred to a later point when interrupts are enabled~\cite{lkd2}.

Upon frame reception, the hardware interrupt handler of the network adapter
performs the following immediate tasks:~\cite{understanding-internals}
\begin{enumerate}
\item Copies the frame into an {\it{sk\_buff}} data structure.
If DMA is used by the device, the kernel needs only to initialise a buffer and pass its descriptors to the driver,
which instructs the device to use DMA.
The received frame is then copied by a DMA transfer.
\item Initialises some of the {\it{sk\_buff}} members for later usage by upper network layers,
notably the {\it{protocol}} member, which identifies the higher-layer protocol handler and will play a major role later.
\item Updates some other parameters private to the device, such as variables for statistical purposes.
\item Signals the kernel about the new frame by scheduling the NET\_RX\_SOFTIRQ softirq for execution.
\end{enumerate}

To keep the execution of the handler as short as possible,
further frame processing is performed later in the NET\_RX\_SOFTIRQ routine.
This softirq routine actually performs an interrupt-related work
not performed in the hardware interrupt handler~\cite{understanding-internals}.
The routine further passes the received frame
to the corresponding L3 protocol handler according to the {\it{protocol}} member of the {\it{skb}}~\cite{lkd2}.
In case of IPv4, this is the {\it{ip\_rcv()}} function described in section~\ref{sec:linux-routing}.
Moreover, the softirq routine is threaded and can run concurrently on different CPUs~\cite{lkd2}.

However, such method of packet processing became insufficient with the emerge of high-speed network cards.
Even a moderately busy interface can handle thousands of packets per second
and per-packet interrupts quickly overwhelm the processor with interrupt-handling work~\cite{low-latency-ethernet-device-polling}.
On the way towards high-speed packet processing on the host CPU,
packet processing in the network stack must have been adapted.

NAPI ("New API", though not so new anymore)
is an interrupt mitigation mechanism used with network devices~\cite{reworking-napi}.
NAPI mixes interrupts with polling and gives higher performance under high traffic load
than the old approach, by reducing significantly the load on the CPU~\cite{understanding-internals}.

\input{linux/ingress-napi.tex}

\input{linux/ingress-offloads.tex}
