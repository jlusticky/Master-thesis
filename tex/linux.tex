%=========================================================================
% (c) 2014, 2015 Josef Lusticky

\chapter{Linux Kernel Packet Processing}

Linux version 3.10 consists of nearly 17 million lines of code.
http://www.cnet.com/news/linux-development-by-the-numbers-big-and-getting-bigger/

Processing packets in the Linux kernel.
There are two modes of processing packets from NIC.
The traditional way is interrupt-driven - each incomming packet is an
asynchronous event which causes interrupt.

The poll method introduced in the New API (NAPI) - only the first incomming packet causes interrupt
and other packets are polled.
NAPI is designed to improve the performance of high-speed networking.
The driver using NAPI provides the poll function to the kernel for reading received packets.

Most of the new drivers support this feature.
When under a heavy load, the packets are lost because of not enough space in NIC buffer.
The packets to be lost are not fed into the network stack, so they take no CPU time.
http://www.haifux.org/lectures/172/netLec.pdf


TCP Segment Offload - kernel is not dealing with segmenting.
ethtool -K eth1 tso on
ethtool -k eth1


\section{NAPI}

NAPI is a proven (www.cyberus.ca/~hadi/usenix-paper.tgz) technique
to improve network performance on Linux.
http://lwn.net/2002/0321/a/napi-howto.php3
---

NAPI ("New API", though it is not so new anymore, since linux kernel 2.6) is an extension to the device driver packet processing framework, which is designed to improve the performance of high-speed networking~\cite{linux-foundation-napi}.

NAPI works through:

Interrupt mitigation (coalescing)
 Improves throughput but degrades latency.
    High-speed networking can create thousands of interrupts per second, all of which tell the system something it already knew: it has lots of packets to process. NAPI allows drivers to run with (some) interrupts disabled during times of high traffic, with a corresponding decrease in system load.

Packet throttling 
    When the system is overwhelmed and must drop packets, it's better if those packets are disposed of before much effort goes into processing them. NAPI-compliant drivers can often cause packets to be dropped in the network adaptor itself, before the kernel sees them at all.

More careful packet treatment, with special care taken to avoid reordering packets. Out-of-order packets can be a significant performance bottleneck. 


NAPI additions to the kernel do not break backward compatibility and drivers may still process completions directly in interrupt context if necessary.

http://lwn.net/Articles/30107/

-----


NAPI is an interrupt mitigation mechanism used with network devices. When network traffic is heavy, the kernel can safely predict that incoming packets will be available anytime it gets around to looking, so there is no need to have the adapter interrupting it (possibly thousands of times per second) to tell it about those packets. So a NAPI-compliant driver will turn off the packet receive interrupt and provide a poll() method to the kernel. When the kernel is ready to deal with more packets, poll() will be called with a maximum number of packets it is allowed to feed into the kernel; it should process up to that many packets and quit.
http://lwn.net/Articles/214457/

-----

Network interfaces, like most reasonable peripheral devices, are capable of interrupting the CPU whenever a packet arrives. But even a moderately busy interface can handle hundreds or thousands of packets per second; per-packet interrupts would quickly overwhelm the processor with interrupt-handling work, leaving little time for getting useful tasks done. So most interface drivers will disable the per-packet interrupt when the traffic level is high enough and, with cooperation from the core networking stack, occasionally poll the device for new packets. There are a number of advantages to doing things this way: vast numbers of interrupts can be avoided, incoming packets can be more efficiently processed in batches, and, if packets must be dropped in response to load, they can be discarded in the interface before they ever hit the network stack. Polling is thus a win for almost all situations where there is any significant amount of traffic at all. 
http://lwn.net/Articles/551284/

---

NAPI is pretty good, but optimized for throughput

Latency is high by default (especially for Ethernet)
Jitter is unpredictable by default

netperf

http://www.linuxplumbersconf.org/2012/wp-content/uploads/2012/09/2012-lpc-Low-Latency-Sockets-slides-brandeburg.pdf

----

It is also possible to use NAPI in wireless 802.11 drivers.
